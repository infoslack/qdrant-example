{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3c2c10-d095-4074-acb5-f6074aed9b6d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51166b8-dbf0-4b34-87b3-70b3a41f1558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import openai\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cc5e4-930a-4793-8a57-f6750d94cea2",
   "metadata": {},
   "source": [
    "### Parse document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf264051-60cd-4f8d-a6d7-d2d3f910e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext = \"\"\n",
    "with pdfplumber.open(\"resume-2024.pdf\") as pdf:\n",
    "    # loop over all the pages\n",
    "    for page in pdf.pages:\n",
    "        fulltext += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a457bf-b559-4c4f-a18f-1df61ad18105",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = fulltext\n",
    "\n",
    "chunks = []\n",
    "while len(text) > 500:\n",
    "    last_period_index = text[:500].rfind('.')\n",
    "    if last_period_index == -1:\n",
    "        last_period_index = 500\n",
    "    chunks.append(text[:last_period_index])\n",
    "    text = text[last_period_index+1:]\n",
    "chunks.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54111064-5bf8-4c04-a656-28679e04e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFour years ago, in a recent shift to machine learning, I deepened myAIskillsetanddeployedrobustMLmodelsinproduction\\nenvironments. Eager to leverage this well-rounded experience, I seek a full-time data scientist or machine learning engineer\\nrole.I'mexcitedtocombinemyvastexperiencebyaddingvaluetoanewjourney\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63013188-60ee-4fde-8cfe-e1034502e54b",
   "metadata": {},
   "source": [
    "### Qdrant connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9380f331-cb70-4bc1-b230-3229c78248b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = os.getenv(\"QDRANT_URL\")\n",
    "api_key = os.getenv(\"QDRANT_KEY\")\n",
    "port = 6333\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=url,\n",
    "    port=port,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=\"demo\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecaeaa2-a9b1-4f59-ab5d-a73cd7aec6bb",
   "metadata": {},
   "source": [
    "### Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a082fa-06d1-475b-9011-1283db3f7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "i = 1\n",
    "for chunk in chunks:\n",
    "    i += 1\n",
    "    \n",
    "    embeddings = openai.embeddings.create(\n",
    "        input=chunk,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    ).data[0].embedding\n",
    "\n",
    "    points.append(PointStruct(id=i, vector=embeddings, payload={\"text\": chunk}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f26240d-d93f-4a1e-af98-88a0e63a5ef2",
   "metadata": {},
   "source": [
    "### Index the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb94166-dca2-4f0a-a0fc-cce18a7cbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_info = qdrant_client.upsert(\n",
    "    collection_name=\"demo\",\n",
    "    wait=True,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c193e-6f4e-41cf-977d-303d8471c95e",
   "metadata": {},
   "source": [
    "### Query index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46703658-8e6c-4201-a68c-5aa89ebc9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer_with_context(query):\n",
    "    embeddings = openai.embeddings.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    ).data[0].embedding\n",
    "\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=\"demo\",\n",
    "        query_vector=embeddings, \n",
    "        limit=3\n",
    "    )\n",
    "\n",
    "    prompt = \"\"\"You are a helpful HR assistant who answers \n",
    "                questions in brief based on the context below.\n",
    "                Context:\\n\"\"\"\n",
    "    for result in search_result:\n",
    "        prompt += result.payload['text'] + \"\\n---\\n\"\n",
    "    prompt += \"Question:\" + query + \"\\n---\\n\" + \"Answer:\"\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480fea2d-f89e-4181-a5c7-731c0321e57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than two decades.\n"
     ]
    }
   ],
   "source": [
    "input = \"How many years of experience does Daniel have?\"\n",
    "answer = create_answer_with_context(input)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c9f573-6419-4cc8-8ddb-5426a0597fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four years ago.\n"
     ]
    }
   ],
   "source": [
    "input = \"When did Daniel shift to Machine Learning?\"\n",
    "answer = create_answer_with_context(input)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d8e6f-dc0a-408f-9093-31f0a47f9314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
